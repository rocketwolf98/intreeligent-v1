{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa424e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kennywan/Documents/intreeligent-v1/.venv/lib64/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import modal\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ae49524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Modal App for intreeligent\n",
    "app = modal.App(\"intreeligent-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7d59c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Modal image\n",
    "image = (\n",
    "    modal.Image.debian_slim(python_version=\"3.13.7\")\n",
    "    .pip_install_from_requirements(\"requirements.txt\")\n",
    "    .apt_install(\"libgl1-mesa-glx\" \"libglib2.0-0\")  # for cv2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483b3312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create volume for data\n",
    "volume = modal.Volume.from_name(\"treesdataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c5a7d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting XML annotations to masks\n",
    "def xml_to_mask(xml_path, img_shape):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "\n",
    "    for obj in root.findall('.//object'):\n",
    "        tree_element = obj.find('tree')\n",
    "        if tree_element is not None:\n",
    "            bbox = obj.find('bndbox')\n",
    "            if bbox is not None:\n",
    "                xmin = int(bbox.find('xmin').text)\n",
    "                ymin = int(bbox.find('ymin').text)\n",
    "                xmax = int(bbox.find('xmax').text)\n",
    "                ymax = int(bbox.find('ymax').text)\n",
    "                \n",
    "                center_x = (xmin + xmax) // 2\n",
    "                center_y = (ymin + ymax) // 2\n",
    "                width = (xmax - xmin) // 2\n",
    "                height = (ymax - ymin) // 2\n",
    "\n",
    "                cv2.ellipse(mask, (center_x, center_y), (width, height), 0, 0, 360, 1, -1)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b2b287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeDataset(Dataset):\n",
    "    def __init__(self, image_dir, xml_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.xml_dir = xml_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(('.tif', '.tiff', '.jpg', '.png'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        xml_name = img_name.replace('.tif', '.xml').replace('.tiff', '.xml').replace('.jpg', '.xml').replace('.png', '.xml')\n",
    "        xml_path = os.path.join(self.xml_dir, xml_name)\n",
    "\n",
    "        image_array = np.array(image)\n",
    "        mask = xml_to_mask(xml_path, image_array.shape)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc9c41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tree_features(image, mask):\n",
    "    \"\"\"Extract features for each tree in the mask.\"\"\"\n",
    "    features_list = []\n",
    "    contours, _ = cv2.findContours(mask.numpy().astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) < 50:\n",
    "            continue\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        tree_region = image[y:y+h, x:x+w]\n",
    "        tree_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "        cv2.filPoly(tree_mask, contour - [x, y], 1)\n",
    "\n",
    "        features = []\n",
    "\n",
    "        for channel in range(3):\n",
    "            channel_pixels = tree_region[:, :, channel][tree_mask > 0]\n",
    "            if len(channel_pixels) > 0:\n",
    "                features.append(np.mean(channel_pixels))\n",
    "                features.append(np.std(channel_pixels))\n",
    "            else:\n",
    "                features.extend([0,0])\n",
    "\n",
    "        area = cv2.contourArea(contour)\n",
    "        features.append(area)\n",
    "        features.append(w/h)\n",
    "\n",
    "        features_list.append(features)\n",
    "\n",
    "    return np.array(features_list)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4bae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will execute with Modal functions\n",
    "@app.function(\n",
    "    image=image,\n",
    "    gpu=\"A100\",\n",
    "    memory=32768,\n",
    "    timeout=3600,\n",
    "    volumes={\"/data\": volume}\n",
    ")\n",
    "\n",
    "def upload_data():\n",
    "    print(\"Please upload your dataset to /data/ using Modal CLI\")\n",
    "    print(\" Modal volume put treesdataset local/path/to/train /data/train\")\n",
    "    print(\" Modal volume put treesdataset local/path/to/annotations /data/annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25261158",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.function(\n",
    "    image=image,\n",
    "    gpu=\"A100\",\n",
    "    memory=32768,\n",
    "    timeout=7200,\n",
    "    volumes={\"/data\": volume}\n",
    ")\n",
    "\n",
    "def train_model():\n",
    "    print(\"Starting model training...\")\n",
    "\n",
    "    IMAGE_DIR = \"/data/train\"\n",
    "    XML_DIR = \"/data/annotations\"\n",
    "\n",
    "    if not os.path.exists(IMAGE_DIR) or not os.path.exists(XML_DIR):\n",
    "        raise FileNotFoundError(\"Image or XML directory not found in /data/. Please upload your dataset.\")\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    dataset = TreeDataset(IMAGE_DIR, XML_DIR, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "\n",
    "    print(f\"Dataset: {len(dataset)} samples, {len(dataloader)} batches\")\n",
    "\n",
    "    model = smp.Unet(encoder_name=\"resnet34\", \n",
    "                     encoder_weights=\"imagenet\", \n",
    "                     in_channels=3, \n",
    "                     classes=2).cuda()\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
